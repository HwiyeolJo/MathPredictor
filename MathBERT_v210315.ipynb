{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MathBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "Index = str(\"4\") # GPU Index/Indices\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= Index\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import *\n",
    "import utils\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "# model_name_or_path = 'allenai/scibert_scivocab_cased'\n",
    "model_name_or_path = 'bert-base-cased'\n",
    "PrecedingSentNum = 7\n",
    "SucceedingSentNum = 0\n",
    "AddNotationToVocab = True\n",
    "\n",
    "data_files = {}\n",
    "\n",
    "data_files[\"train\"] = \"../../Data/features_s2orc_external_cs_limit=1000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "AddNotationsToVocab\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222401/222401 [00:01<00:00, 165535.24it/s]\n",
      "  6%|▋         | 33/526 [00:00<00:01, 325.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddedTokens ['\\\\rightrightarrows', '\\\\subsetneqq', '\\\\deg', '\\\\blacksquare', '\\\\bowtie', '\\\\lim', '\\\\uplus', '\\\\eta', '\\\\textsf', '\\\\bigoplus', '\\\\rightarrow', '\\\\cr', '\\\\cap', '\\\\vphantom', '\\\\vee', '\\\\mid', '\\\\of', '\\\\textmd', '\\\\mathbfcal', '\\\\dots', '\\\\Psi', '\\\\mathbin', '\\\\right\\\\Vert', '\\\\ogreaterthan', '\\\\mathbf', '\\\\tt', '\\\\iint', '\\\\cup', '\\\\\\\\a', '\\\\\\\\v\\\\\\\\w', '\\\\iff', '\\\\\\\\\\\\qquad', '\\\\cite', '\\\\diagdown', '\\\\mu', '\\\\overrightarrow', '\\\\mbox', '\\\\makebox', '\\\\Bigm', '\\\\\\\\\\\\\\\\', '\\\\it', '\\\\scshape', '\\\\color', '\\\\leqslant', '\\\\index', '\\\\normalfont', '\\\\left\\\\Vert', '\\\\left\\\\lfloor', '\\\\div', '\\\\acute', '\\\\textstyle', '\\\\dashv', '\\\\ker', '\\\\Re', '\\\\small', '\\\\bigtriangleup', '\\\\spadesuit', '\\\\left\\\\bad', '\\\\dag', '\\\\\\\\\\\\nonumber', '\\\\bot', '\\\\complement', '\\\\Huge', '\\\\simeq', '\\\\ne', '\\\\phantom', '\\\\odot', '\\\\em', '\\\\left\\\\lbrace', '\\\\rightsquigarrow', '\\\\\\\\w', '\\\\footnotesize', '\\\\langle', '\\\\hline', '\\\\\\\\\\\\mathbf', '\\\\\\\\K', '\\\\textbf', '\\\\pazocal', '\\\\frac', '\\\\ddot', '\\\\\\\\\\\\bar', '\\\\nprec', '\\\\nu', '\\\\hat', '\\\\Pr', '\\\\rbrace', '\\\\selectfont', '\\\\operatorname', '\\\\error', '\\\\multimap', '\\\\aleph', '\\\\exp', '\\\\vert', '\\\\\\\\\\\\theta', '\\\\sharp', '\\\\Im', '\\\\footnote', '\\\\wr', '\\\\nolimits', '\\\\\\\\N', '\\\\dot', '\\\\exists', '\\\\colon', '\\\\includegraphics', '\\\\\\\\H', '\\\\tilde', '\\\\sc', '\\\\\\\\\\\\ldots', '\\\\Omega', '\\\\vdots', '\\\\ominus', '\\\\leavevmode', '\\\\genfrac\\\\langle', '\\\\subseteq', '\\\\bmod', '\\\\ref', '\\\\nexists', '\\\\nearrow', '\\\\square', '\\\\ni', '\\\\lozenge', '\\\\ggg', '\\\\lg', '\\\\textup', '\\\\searrow', '\\\\textnormal', '\\\\\\\\Notice', '\\\\tiny', '\\\\medskip', '\\\\forall', '\\\\right\\\\rbrace', '\\\\unknown', '\\\\cos', '\\\\paragraph', '\\\\bigsqcup', '\\\\limits', '\\\\colorbox', '\\\\anodecurve', '\\\\sbox', '\\\\supseteq', '\\\\rotatebox', '\\\\iota', '\\\\doteq', '\\\\newline', '\\\\pmod', '\\\\varphi', '\\\\llparenthesis', '\\\\\\\\q', '\\\\underset', '\\\\sigma', '\\\\biggr', '\\\\rho', '\\\\arccos', '\\\\right\\\\rfloor', '\\\\upsilon', '\\\\varpi', '\\\\star', '\\\\setminus', '\\\\partial', '\\\\prod', '\\\\scriptstyle', '\\\\dbinom', '\\\\linebreak', '\\\\longleftrightarrow', '\\\\mathsf', '\\\\pm', '\\\\nvDash', '\\\\grave', '\\\\blacktriangleright', '\\\\\\\\v', '\\\\mathfrak', '\\\\\\\\p\\\\end', '\\\\\\\\\\\\mathcal', '\\\\Sigma', '\\\\parallel', '\\\\longleftarrow', '\\\\boxed', '\\\\hspace', '\\\\mathit', '\\\\\\\\X', '\\\\varepsilon', '\\\\ding', '\\\\\\\\\\\\Omega', '\\\\lneq', '\\\\le', '\\\\intercal', '\\\\olessthan', '\\\\left', '\\\\alpha', '\\\\xbox', '\\\\rrparenthesis', '\\\\epsilon', '\\\\textrm', '\\\\oplus', '\\\\succcurlyeq', '\\\\varrho', '\\\\scalebox', '\\\\dotplus', '\\\\hfil', '\\\\uparrow', '\\\\oint', '\\\\imath', '\\\\Delta', '\\\\quad', '\\\\lnot', '\\\\propto', '\\\\sim', '\\\\log', '\\\\Vert', '\\\\itshape', '\\\\framebox', '\\\\longrightarrow', '\\\\leftrightharpoons', '\\\\usefont', '\\\\\\\\\\\\omega', '\\\\chi', '\\\\dim', '\\\\subset', '\\\\phi', '\\\\\\\\\\\\Leftrightarrow', '\\\\Bigl', '\\\\nabla', '\\\\\\\\\\\\lbrace', '\\\\\\\\p', '\\\\overset', '\\\\\\\\\\\\', '\\\\preccurlyeq', '\\\\models', '\\\\Rightarrow', '\\\\qquad', '\\\\psi', '\\\\\\\\u\\\\ne', '\\\\\\\\A', '\\\\inf', '\\\\cdot', '\\\\nsucc', '\\\\right', '\\\\vdash', '\\\\\\\\\\\\sf', '\\\\mathord', '\\\\theta', '\\\\gtrsim', '\\\\min', '\\\\tfrac', '\\\\Theta', '\\\\curvearrowright', '\\\\centerdot', '\\\\pi', '\\\\triangleq', '\\\\underaccent', '\\\\arctan', '\\\\nsubseteq', '\\\\ddag', '\\\\XMLaddatt', '\\\\wp', '\\\\centering', '\\\\over', '\\\\gtrless', '\\\\cosh', '\\\\binom', '\\\\nmid', '\\\\\\\\\\\\tilde', '\\\\crcr', '\\\\widehat', '\\\\biguplus', '\\\\ddots', '\\\\triangle', '\\\\varnothing', '\\\\sqcup', '\\\\boxplus', '\\\\smile', '\\\\bigtriangledown', '\\\\hbox', '\\\\\\\\\\\\hat', '\\\\lhd', '\\\\text', '\\\\limsup', '\\\\gcd', '\\\\mathrm', '\\\\\\\\\\\\phantom', '\\\\angle', '\\\\mathchoice', '\\\\qopname', '\\\\cong', '\\\\downarrow', '\\\\cal', '\\\\ll', '\\\\supset', '\\\\rceil', '\\\\sum', '\\\\lbrace', '\\\\nrightarrow', '\\\\Gamma', '\\\\bigtimes', '\\\\circledcirc', '\\\\ast', '\\\\textit', '\\\\\\\\\\\\gamma', '\\\\leadsto', '\\\\measuredangle', '\\\\left\\\\lceil', '\\\\diamondsuit', '\\\\jmath', '\\\\gamma', '\\\\mathtt', '\\\\curvearrowleft', '\\\\backslash', '\\\\widetilde', '\\\\csc', '\\\\Longrightarrow', '\\\\upharpoonright', '\\\\in', '\\\\ell', '\\\\lambda', '\\\\liminf', '\\\\lceil', '\\\\sqsubseteq', '\\\\\\\\C', '\\\\\\\\v\\\\ne', '\\\\mathpzc', '\\\\triangledown', '\\\\varliminf', '\\\\delta', '\\\\breve', '\\\\parbox', '\\\\circledast', '\\\\genfrac', '\\\\mathring', '\\\\mathnormal', '\\\\precsim', '\\\\vspace', '\\\\Leftrightarrow', '\\\\hfill', '\\\\mapsto', '\\\\right\\\\rangle', '\\\\\\\\\\\\chi', '\\\\item', '\\\\varsigma', '\\\\rfloor', '\\\\Bigr', '\\\\texttt', '\\\\Biggr', '\\\\\\\\p\\\\\\\\q', '\\\\subsection', '\\\\succeq', '\\\\\\\\e', '\\\\overbrace', '\\\\bigl', '\\\\dashrightarrow', '\\\\atop', '\\\\approx', '\\\\mathopen', '\\\\box', '\\\\mathbb', '\\\\mathinner', '\\\\vrule', '\\\\genfrac\\\\Vert', '\\\\nonumber', '\\\\leftarrow', '\\\\sf', '\\\\cot', '\\\\Large', '\\\\\\\\It', '\\\\raisebox', '\\\\emph', '\\\\rightharpoonup', '\\\\diamond', '\\\\Upsilon', '\\\\section', '\\\\ddagger', '\\\\\\\\\\\\infty', '\\\\rm', '\\\\Longleftrightarrow', '\\\\Lambda', '\\\\atopwithdelims', '\\\\subsetneq', '\\\\vartheta', '\\\\protect', '\\\\mathop', '\\\\prime', '\\\\lfloor', '\\\\sup', '\\\\Phi', '\\\\\\\\i', '\\\\llbracket', '\\\\textsuperscript', '\\\\emptyset', '\\\\underline', '\\\\longmapsto', '\\\\Pi', '\\\\scriptscriptstyle', '\\\\max', '\\\\triangleleft', '\\\\underbrace', '\\\\multicolumn', '\\\\caption', '\\\\bigg', '\\\\mathrel', '\\\\because', '\\\\ldots', '\\\\\\\\I', '\\\\\\\\', '\\\\bigotimes', '\\\\sqcap', '\\\\\\\\L', '\\\\bibitem', '\\\\ge', '\\\\oslash', '\\\\\\\\\\\\sigma', '\\\\eth', '\\\\succ', '\\\\stackrel', '\\\\dfrac', '\\\\\\\\\\\\frac', '\\\\nodeconnect', '\\\\\\\\\\\\hline', '\\\\circlearrowright', '\\\\rhd', '\\\\omega', '\\\\ln', '\\\\subsubsection', '\\\\Longleftarrow', '\\\\rule', '\\\\gg', '\\\\\\\\C\\\\end', '\\\\vec', '\\\\big', '\\\\bullet', '\\\\supsetneq', '\\\\cline', '\\\\det', '\\\\bar', '\\\\\\\\\\\\end', '\\\\textsl', '\\\\cdots', '\\\\m', '\\\\perp', '\\\\dagger', '\\\\Xi', '\\\\\\\\\\\\vdots', '\\\\xrightarrow', '\\\\mathclose', '\\\\Leftarrow', '\\\\\\\\b', '\\\\Biggl', '\\\\geqslant', '\\\\therefore', '\\\\hookrightarrow', '\\\\vtop', '\\\\rrbracket', '\\\\overline', '\\\\bf', '\\\\tau', '\\\\bfseries', '\\\\genfrac\\\\lbrace', '\\\\\\\\B', '\\\\overleftarrow', '\\\\preceq', '\\\\displaylimits', '\\\\mod', '\\\\zeta', '\\\\Subset', '\\\\sin', '\\\\int', '\\\\displaystyle', '\\\\\\\\\\\\mathsf', '\\\\prec', '\\\\top', '\\\\bigcap', '\\\\end', '\\\\\\\\\\\\zeta', '\\\\\\\\x', '\\\\\\\\Q', '\\\\sqrt', '\\\\check', '\\\\succsim', '\\\\left\\\\langle', '\\\\triangleright', '\\\\varlimsup', '\\\\sinh', '\\\\right\\\\rceil', '\\\\equiv', '\\\\asymp', '\\\\tanh', '\\\\xi', '\\\\mathcal', '\\\\rangle', '\\\\smash', '\\\\\\\\\\\\text', '\\\\biggl', '\\\\lessapprox', '\\\\textsc', '\\\\Bigg', '\\\\beta', '\\\\Box', '\\\\heartsuit', '\\\\mp', '\\\\bumpeq', '\\\\Big', '\\\\otimes', '\\\\\\\\\\\\alpha', '\\\\leftrightarrow', '\\\\wedge', '\\\\times', '\\\\kappa', '\\\\arcsin', '\\\\ltimes', '\\\\bigwedge', '\\\\bigcup', '\\\\tan', '\\\\circ', '\\\\lesssim', '\\\\notin', '\\\\\\\\D', '\\\\\\\\s', '\\\\bigvee', '\\\\infty', '\\\\diagup', '\\\\scriptsize', '\\\\bigr', '\\\\begin', '\\\\node', '\\\\arg', '\\\\nleq', '\\\\hdots', '\\\\operatornamewithlimits']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 526/526 [00:01<00:00, 314.99it/s]\n",
      "  0%|          | 52/222401 [00:00<07:13, 513.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Prepare Data\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222401/222401 [07:23<00:00, 501.75it/s] \n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "### Add Custom Vocabs\n",
    "tokenizer.add_tokens([\"SYMBOL\"])\n",
    "tokenizer.add_tokens([\"SECTION\"])\n",
    "tokenizer.add_tokens([\"EQUATION\"])\n",
    "tokenizer.add_tokens([\"CITATION\"])\n",
    "tokenizer.add_tokens([\"$$\"])\n",
    "\n",
    "# SplitMethod can be \"ByPaperID\", \n",
    "PreprocessedData, added_tokens = utils.Preprocessing(tokenizer, data_files[\"train\"], SplitMethod=\"ByPaperID\",\n",
    "                                       PrecedingSentNum=PrecedingSentNum, SucceedingSentNum=SucceedingSentNum,\n",
    "                                       AddNotationToVocab=AddNotationToVocab)\n",
    "tokenizer.add_tokens(added_tokens)\n",
    "train_src, train_tgt, valid_src, valid_tgt, test_src, test_tgt = PreprocessedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "MaxTokenLen = 512\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    examples[\"text\"] = tokenizer.convert_tokens_to_string(examples[\"text\"].split())\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=False,\n",
    "        max_length=MaxTokenLen,\n",
    "        add_special_tokens = False,\n",
    "        return_special_tokens_mask=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration\n",
    "model_name_or_path = 'bert-base-cased'\n",
    "\n",
    "Verbose = True\n",
    "MaskNumConstraint = 10\n",
    "FineTune = True\n",
    "Test = True\n",
    "EpochNum = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dcba6ad9d040628c4cc185d055093b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2429, device='cuda:0', grad_fn=<DivBackward0>))0>)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyjo/.local/lib/python3.6/site-packages/ipykernel_launcher.py:40: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20\tLoss:1.7341evice='cuda:0', grad_fn=<DivBackward0>))0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039f83b4da874f69802e0d0c4fdeba79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 140045.0 / 195005 0.7181610727930053\n",
      "Top-1 Accuracy 0.7181610727930053\n",
      "Top-2 Accuracy 0.7770159739493859\n",
      "Top-3 Accuracy 0.8053485808056203\n",
      "Top-4 Accuracy 0.8244968077741597\n",
      "Top-5 Accuracy 0.8387477244173226\n",
      "Top-6 Accuracy 0.8499423091715597\n",
      "Top-7 Accuracy 0.8592497628265942\n",
      "Top-8 Accuracy 0.8671572523781441\n",
      "Top-9 Accuracy 0.8738647726981359\n",
      "Top-10 Accuracy 0.8797415450885875\n",
      "Perplexity(MASK) 4.770176012085848\n",
      "Model Saving in ./save/Left3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/20\tLoss:1.2780evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864195263f2347e3b37fbe6c2d7ab663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143890.0 / 195005 0.7378785159354888\n",
      "Top-1 Accuracy 0.7378785159354888\n",
      "Top-2 Accuracy 0.7935334991410476\n",
      "Top-3 Accuracy 0.8209584369631547\n",
      "Top-4 Accuracy 0.8397784672187892\n",
      "Top-5 Accuracy 0.8541165611138176\n",
      "Top-6 Accuracy 0.86510089484885\n",
      "Top-7 Accuracy 0.8742852747365453\n",
      "Top-8 Accuracy 0.8813517602112766\n",
      "Top-9 Accuracy 0.8873875028845414\n",
      "Top-10 Accuracy 0.8929463347093665\n",
      "Perplexity(MASK) 4.770283215645581\n",
      "Model Saving in ./save/Left3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/20\tLoss:1.1359evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5baa1b0be6c4d2084b318878a044f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144868.0 / 195005 0.7428937719545653\n",
      "Top-1 Accuracy 0.7428937719545653\n",
      "Top-2 Accuracy 0.7974923719904617\n",
      "Top-3 Accuracy 0.8259377964667572\n",
      "Top-4 Accuracy 0.8442501474321171\n",
      "Top-5 Accuracy 0.8577062126612138\n",
      "Top-6 Accuracy 0.8687623394271942\n",
      "Top-7 Accuracy 0.8773005820363581\n",
      "Top-8 Accuracy 0.8843209148483372\n",
      "Top-9 Accuracy 0.8906694700135894\n",
      "Top-10 Accuracy 0.8964385528576191\n",
      "Perplexity(MASK) 4.770297205057709\n",
      "Model Saving in ./save/Left3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/20\tLoss:1.0276evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64a9a6845c6493d9d3839a2903c24d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144837.0 / 195005 0.742734801671752\n",
      "Top-1 Accuracy 0.742734801671752\n",
      "Top-2 Accuracy 0.7982769672572498\n",
      "Top-3 Accuracy 0.8261480474859619\n",
      "Top-4 Accuracy 0.8447014179123612\n",
      "Top-5 Accuracy 0.8585779851798672\n",
      "Top-6 Accuracy 0.8694289890002821\n",
      "Top-7 Accuracy 0.8778646701366631\n",
      "Top-8 Accuracy 0.8852234558088254\n",
      "Top-9 Accuracy 0.8914232968385426\n",
      "Top-10 Accuracy 0.8967462372759673\n",
      "Perplexity(MASK) 4.770350409970787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/20\tLoss:0.9338evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e271a4b02246f4a55c4532ef92b5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144686.0 / 195005 0.7419604625522422\n",
      "Top-1 Accuracy 0.7419604625522422\n",
      "Top-2 Accuracy 0.7965590625881388\n",
      "Top-3 Accuracy 0.8251429450526909\n",
      "Top-4 Accuracy 0.8437373400682033\n",
      "Top-5 Accuracy 0.8575421143047615\n",
      "Top-6 Accuracy 0.8684751673034025\n",
      "Top-7 Accuracy 0.8771826363426579\n",
      "Top-8 Accuracy 0.8844286043947591\n",
      "Top-9 Accuracy 0.8906745980872285\n",
      "Top-10 Accuracy 0.8959924104510141\n",
      "Perplexity(MASK) 4.770400250063041\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20\tLoss:0.8488evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5c043ed0d141b7889fec092d9df1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144831.0 / 195005 0.7427040332299172\n",
      "Top-1 Accuracy 0.7427040332299172\n",
      "Top-2 Accuracy 0.7968411066382913\n",
      "Top-3 Accuracy 0.8237173405810108\n",
      "Top-4 Accuracy 0.8423219917438014\n",
      "Top-5 Accuracy 0.8559677956975462\n",
      "Top-6 Accuracy 0.8667008538242609\n",
      "Top-7 Accuracy 0.8753006333170944\n",
      "Top-8 Accuracy 0.8823466064972693\n",
      "Top-9 Accuracy 0.888490038716956\n",
      "Top-10 Accuracy 0.8939668213635548\n",
      "Perplexity(MASK) 4.770463049876609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/20\tLoss:0.7732evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7d261065c04efdb473b6fc6431992b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144466.0 / 195005 0.740832286351632\n",
      "Top-1 Accuracy 0.740832286351632\n",
      "Top-2 Accuracy 0.7947078280044101\n",
      "Top-3 Accuracy 0.8216917514935514\n",
      "Top-4 Accuracy 0.8398964129124894\n",
      "Top-5 Accuracy 0.853198635932412\n",
      "Top-6 Accuracy 0.863834260659983\n",
      "Top-7 Accuracy 0.8724750647419297\n",
      "Top-8 Accuracy 0.8799671803287096\n",
      "Top-9 Accuracy 0.8865464988077228\n",
      "Top-10 Accuracy 0.8919463603497346\n",
      "Perplexity(MASK) 4.770453070554677\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/20\tLoss:0.7013evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b41c117b91d4409a8f4937f8d7400c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144720.0 / 195005 0.742134817055973\n",
      "Top-1 Accuracy 0.742134817055973\n",
      "Top-2 Accuracy 0.7942821978923618\n",
      "Top-3 Accuracy 0.820481526114715\n",
      "Top-4 Accuracy 0.8380605625496782\n",
      "Top-5 Accuracy 0.8510397169303351\n",
      "Top-6 Accuracy 0.8609779236429835\n",
      "Top-7 Accuracy 0.8693059152329428\n",
      "Top-8 Accuracy 0.8767005974205789\n",
      "Top-9 Accuracy 0.8828389015666265\n",
      "Top-10 Accuracy 0.8880951770467423\n",
      "Perplexity(MASK) 4.770519262318138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/20\tLoss:0.6359evice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4354001f022247519d915ef075332a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144429.0 / 195005 0.7406425476269839\n",
      "Top-1 Accuracy 0.7406425476269839\n",
      "Top-2 Accuracy 0.7926617266223943\n",
      "Top-3 Accuracy 0.8188815671393042\n",
      "Top-4 Accuracy 0.8364759877951847\n",
      "Top-5 Accuracy 0.849321812261224\n",
      "Top-6 Accuracy 0.8598600035896515\n",
      "Top-7 Accuracy 0.8684136304197329\n",
      "Top-8 Accuracy 0.8752596087279814\n",
      "Top-9 Accuracy 0.8814799620522551\n",
      "Top-10 Accuracy 0.8868900797415451\n",
      "Perplexity(MASK) 4.770506537959315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/20\tLoss:0.5767vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2814d6fab24950b9645fcda8fdcccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144015.0 / 195005 0.738519525140381\n",
      "Top-1 Accuracy 0.738519525140381\n",
      "Top-2 Accuracy 0.7896977000589729\n",
      "Top-3 Accuracy 0.8161431758160047\n",
      "Top-4 Accuracy 0.8335632419681547\n",
      "Top-5 Accuracy 0.8459834363221456\n",
      "Top-6 Accuracy 0.8560806133176072\n",
      "Top-7 Accuracy 0.8645573190431015\n",
      "Top-8 Accuracy 0.8718289274633984\n",
      "Top-9 Accuracy 0.8778185174739109\n",
      "Top-10 Accuracy 0.883192738647727\n",
      "Perplexity(MASK) 4.770620676154674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/20\tLoss:0.5217vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee833b8acb14490788cb71ed44a2e6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 144047.0 / 195005 0.7386836234968334\n",
      "Top-1 Accuracy 0.7386836234968334\n",
      "Top-2 Accuracy 0.7890054101176893\n",
      "Top-3 Accuracy 0.8142304043486065\n",
      "Top-4 Accuracy 0.8310915104740904\n",
      "Top-5 Accuracy 0.8434860644598856\n",
      "Top-6 Accuracy 0.853014025281403\n",
      "Top-7 Accuracy 0.8616343170687931\n",
      "Top-8 Accuracy 0.8685161918925156\n",
      "Top-9 Accuracy 0.8747724417322633\n",
      "Top-10 Accuracy 0.8801928155688316\n",
      "Perplexity(MASK) 4.770718111939788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20\tLoss:0.4737vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00af3a1a118455f8a796f5583be9d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143496.0 / 195005 0.7358580549216687\n",
      "Top-1 Accuracy 0.7358580549216687\n",
      "Top-2 Accuracy 0.7865541909181816\n",
      "Top-3 Accuracy 0.8117586728545422\n",
      "Top-4 Accuracy 0.8288607984410656\n",
      "Top-5 Accuracy 0.8416758544652702\n",
      "Top-6 Accuracy 0.8513217609804877\n",
      "Top-7 Accuracy 0.8594189892566857\n",
      "Top-8 Accuracy 0.8664341939950257\n",
      "Top-9 Accuracy 0.8724750647419297\n",
      "Top-10 Accuracy 0.877669803338376\n",
      "Perplexity(MASK) 4.770684454217437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/20\tLoss:0.4288, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3f844a266b40d3a0249f2052c3f80b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143493.0 / 195005 0.7358426707007513\n",
      "Top-1 Accuracy 0.7358426707007513\n",
      "Top-2 Accuracy 0.7844260403579395\n",
      "Top-3 Accuracy 0.8096561626624958\n",
      "Top-4 Accuracy 0.8257583138893875\n",
      "Top-5 Accuracy 0.8377682623522473\n",
      "Top-6 Accuracy 0.8480244096305223\n",
      "Top-7 Accuracy 0.8562344555267813\n",
      "Top-8 Accuracy 0.8628189020794339\n",
      "Top-9 Accuracy 0.8686751621753288\n",
      "Top-10 Accuracy 0.8736904181944053\n",
      "Perplexity(MASK) 4.770759175650433\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/20\tLoss:0.3916vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f2678b0ab24e5f883004d62d37a861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 142993.0 / 195005 0.7332786338811825\n",
      "Top-1 Accuracy 0.7332786338811825\n",
      "Top-2 Accuracy 0.7819850773057101\n",
      "Top-3 Accuracy 0.807425450629471\n",
      "Top-4 Accuracy 0.8231942770698187\n",
      "Top-5 Accuracy 0.8355067818773878\n",
      "Top-6 Accuracy 0.8454706289582319\n",
      "Top-7 Accuracy 0.8536191379708212\n",
      "Top-8 Accuracy 0.8606138304146047\n",
      "Top-9 Accuracy 0.8664341939950257\n",
      "Top-10 Accuracy 0.8713622727622369\n",
      "Perplexity(MASK) 4.770843298243514\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/20\tLoss:0.3562vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a685b78c19c4397bc0a3115db45c671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143372.0 / 195005 0.7352221737904157\n",
      "Top-1 Accuracy 0.7352221737904157\n",
      "Top-2 Accuracy 0.7827235199097459\n",
      "Top-3 Accuracy 0.8072510961257404\n",
      "Top-4 Accuracy 0.8235378580036409\n",
      "Top-5 Accuracy 0.8355016538037486\n",
      "Top-6 Accuracy 0.845101407656214\n",
      "Top-7 Accuracy 0.8529627445450116\n",
      "Top-8 Accuracy 0.8596805210122818\n",
      "Top-9 Accuracy 0.8653778108253635\n",
      "Top-10 Accuracy 0.8706853670418707\n",
      "Perplexity(MASK) 4.770915974282884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/20\tLoss:0.3263vice='cuda:0', grad_fn=<DivBackward0>)d0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20871025340347e0bcb67fd14afb56bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143201.0 / 195005 0.7343452731981231\n",
      "Top-1 Accuracy 0.7343452731981231\n",
      "Top-2 Accuracy 0.7809492064306044\n",
      "Top-3 Accuracy 0.8046357785697803\n",
      "Top-4 Accuracy 0.8207635701648676\n",
      "Top-5 Accuracy 0.8323068639265659\n",
      "Top-6 Accuracy 0.8416861106125484\n",
      "Top-7 Accuracy 0.8497064177841593\n",
      "Top-8 Accuracy 0.8562498397476987\n",
      "Top-9 Accuracy 0.8620958436963155\n",
      "Top-10 Accuracy 0.8670341786108049\n",
      "Perplexity(MASK) 4.770979901087079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/20\tLoss:0.2999, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01234fdee93466f89a74f2ec098c9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143279.0 / 195005 0.7347452629419758\n",
      "Top-1 Accuracy 0.7347452629419758\n",
      "Top-2 Accuracy 0.7813902207635701\n",
      "Top-3 Accuracy 0.8050306402399938\n",
      "Top-4 Accuracy 0.8210917668777724\n",
      "Top-5 Accuracy 0.8330350503833235\n",
      "Top-6 Accuracy 0.8428553114022718\n",
      "Top-7 Accuracy 0.850439732314556\n",
      "Top-8 Accuracy 0.8569728981308171\n",
      "Top-9 Accuracy 0.8627624932694034\n",
      "Top-10 Accuracy 0.8678803107612625\n",
      "Perplexity(MASK) 4.771026826873388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/20\tLoss:0.2762, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64958c6839ff499bad85fcfed8d8b456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 143031.0 / 195005 0.7334735006794697\n",
      "Top-1 Accuracy 0.7334735006794697\n",
      "Top-2 Accuracy 0.7802620445629599\n",
      "Top-3 Accuracy 0.8041229712058665\n",
      "Top-4 Accuracy 0.8198712853516577\n",
      "Top-5 Accuracy 0.8315940616907259\n",
      "Top-6 Accuracy 0.8406451116638035\n",
      "Top-7 Accuracy 0.8484859362580447\n",
      "Top-8 Accuracy 0.8549985897797492\n",
      "Top-9 Accuracy 0.8607984410656137\n",
      "Top-10 Accuracy 0.865588061844568\n",
      "Perplexity(MASK) 4.77111567217422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20\tLoss:0.2555, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e85dacec23c4481ae428cae651a957e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=216333.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-1 Accuracy 142866.0 / 195005 0.7326273685290121\n",
      "Top-1 Accuracy 0.7326273685290121\n",
      "Top-2 Accuracy 0.77966718802082\n",
      "Top-3 Accuracy 0.8031588933617086\n",
      "Top-4 Accuracy 0.8190200251275608\n",
      "Top-5 Accuracy 0.8307838260557422\n",
      "Top-6 Accuracy 0.8400912797107767\n",
      "Top-7 Accuracy 0.8477269813594523\n",
      "Top-8 Accuracy 0.8539216943155303\n",
      "Top-9 Accuracy 0.85969077715956\n",
      "Top-10 Accuracy 0.8645983436322145\n",
      "Perplexity(MASK) 4.771162248244989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a85cbe2603446488df770e994541d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1910591.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5056, device='cuda:0', grad_fn=<DivBackward0>)d0>)\r"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "from datasets.utils.logging import set_verbosity_error\n",
    "import random\n",
    "import copy\n",
    "\n",
    "### Reload\n",
    "model = AutoModelForMaskedLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    ")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = nn.DataParallel(model).to(device)\n",
    "\n",
    "if FineTune:\n",
    "    LossFunction = nn.CrossEntropyLoss()\n",
    "    Optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.module.parameters()), lr=5e-6)\n",
    "    pbar1 = tqdm(total=EpochNum)\n",
    "    TopAcc = 0.\n",
    "    for ep in range(EpochNum):\n",
    "        ### Variables\n",
    "        total_loss = []\n",
    "        #####\n",
    "        model.train()\n",
    "        pbar2 = tqdm(total=len(train_tgt), leave=False)\n",
    "        for i in range(len(train_tgt)):\n",
    "            MaskNum = np.sum(np.array(train_src[i].split()) == \"[MASK]\")\n",
    "            if MaskNum > MaskNumConstraint: # MASK Length Constraint\n",
    "                pbar2.update(1); continue\n",
    "            elif MaskNum == 0:\n",
    "                pbar2.update(1); continue\n",
    "            DataDict_train = { \"train\": Dataset.from_dict({ \"text\": [' '.join(train_src[i].split()) ] }), }\n",
    "            datasets_train = DatasetDict(DataDict_train)\n",
    "\n",
    "            tokenized_datasets = datasets_train.map(\n",
    "                tokenize_function,\n",
    "                batched=False,\n",
    "                num_proc=1,\n",
    "            )\n",
    "            \n",
    "            pred_token = train_src[i].split()\n",
    "            tgt_token = train_tgt[i].split()\n",
    "            \n",
    "            for _ in range(1): # Partial Masking\n",
    "                for cnt, x in enumerate(tokenized_datasets[\"train\"]):\n",
    "                    MASK_idx = [ii for ii, iids in enumerate(x[\"input_ids\"])\n",
    "                                if iids == tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]]\n",
    "                    outputs = model(torch.tensor(x[\"input_ids\"]).unsqueeze(0).to(device),)\n",
    "\n",
    "                p = []\n",
    "                loss = 0\n",
    "                for m in MASK_idx:\n",
    "                    loss += LossFunction(outputs[\"logits\"][0][m:m+1],\n",
    "                                         torch.tensor(tokenizer.convert_tokens_to_ids([tgt_token[m]])).to(device))\n",
    "                Optimizer.zero_grad()\n",
    "                if loss != 0:\n",
    "                    total_loss.append((loss/len(MASK_idx)).item())\n",
    "                    print(loss/len(MASK_idx), end='\\r')\n",
    "                    loss.backward()\n",
    "                Optimizer.step()\n",
    "            pbar2.update(1)\n",
    "        pbar2.close()\n",
    "        print(\"{}/{}\\tLoss:{:.4f}\".format(ep+1, EpochNum, np.mean(total_loss)))\n",
    "        pbar1.update(1)\n",
    "        \n",
    "        ### Evaluation\n",
    "        model.eval()\n",
    "        \n",
    "        correct, total = 0., 0\n",
    "        correct_topk = np.zeros(10+1)\n",
    "        perplexity_list = []\n",
    "        CorrectFlag = False\n",
    "\n",
    "        pbar = tqdm(total = len(valid_tgt))\n",
    "        for i in range(len(valid_tgt)):\n",
    "            MaskNum = np.sum(np.array(valid_src[i].split()) == \"[MASK]\")\n",
    "            if MaskNum > MaskNumConstraint: # MASK Length Constraint\n",
    "                pbar.update(1); continue\n",
    "            elif MaskNum == 0:\n",
    "                pbar.update(1); continue\n",
    "            DataDict_valid = { \"valid\": Dataset.from_dict({ \"text\": [' '.join(valid_src[i].split()) ] }), }\n",
    "            datasets_valid = DatasetDict(DataDict_valid)\n",
    "\n",
    "            tokenized_datasets = datasets_valid.map(\n",
    "                tokenize_function,\n",
    "                batched=False,\n",
    "                num_proc=1,\n",
    "            )\n",
    "\n",
    "            for cnt, x in enumerate(tokenized_datasets[\"valid\"]):\n",
    "                with torch.no_grad():\n",
    "                    MASK_idx = [ii for ii, iids in enumerate(x[\"input_ids\"])\n",
    "                                if iids == tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]]\n",
    "                    outputs = model(torch.tensor(x[\"input_ids\"]).unsqueeze(0).to(device),)\n",
    "                    \n",
    "                    p = []\n",
    "                    pred_token = valid_src[i].split()\n",
    "                    tgt_token = valid_tgt[i].split()\n",
    "\n",
    "                for m in MASK_idx:\n",
    "                    predicted_index = torch.argmax(outputs[\"logits\"][0][m]).item()\n",
    "                    pred_t = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "#                     pred_token[m] = '[[' + pred_t + ']]' # When Visualization\n",
    "                    pred_token[m] = pred_t\n",
    "                    total += 1\n",
    "                    if tgt_token[m] == pred_t:\n",
    "                        CorrectFlag = True\n",
    "                        correct += 1\n",
    "                    ### Top-k\n",
    "                    pred_topk = []; pred_ts = []\n",
    "                    for n in range(1,10+1): # Starts from Top-1\n",
    "                        pred_topk = torch.argsort(-outputs[\"logits\"][0][m])[:n]\n",
    "                        pred_ts = tokenizer.convert_ids_to_tokens([t for t in pred_topk])\n",
    "                        if tgt_token[m] in pred_ts:\n",
    "                            correct_topk[n] += 1\n",
    "\n",
    "                    exp_t = outputs[\"logits\"][0][m].cpu().numpy()\n",
    "                    # https://huggingface.co/transformers/perplexity.html\n",
    "                    prob = np.exp(exp_t[tokenizer.convert_tokens_to_ids(tgt_token[m])]/len(exp_t))\n",
    "                    p.append(prob)\n",
    "            if p: perplexity_list.append(np.sum(p))\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "        print(correct, '/', total, correct/total)\n",
    "        for n in range(1,10+1):\n",
    "            print(\"Top-\"+str(n), \"Accuracy\", correct_topk[n]/total)\n",
    "        print(\"Perplexity(MASK)\", np.mean(perplexity_list))\n",
    "        \n",
    "        if correct/total > TopAcc:\n",
    "            print(\"Model Saving in ./save/\")\n",
    "            model.module.save_pretrained('./save/')\n",
    "            tokenizer.save_vocabulary(\"./save/\")\n",
    "            TopAcc = correct/total\n",
    "    pbar1.close()\n",
    "    ###\n",
    "\n",
    "if Test:\n",
    "    correct, total = 0., 0\n",
    "    total_loss = []\n",
    "    TopAcc = 0.\n",
    "    correct_topk = np.zeros(10+1)\n",
    "    perplexity_list = []\n",
    "    CorrectFlag = False\n",
    "\n",
    "    print(\"Model Loading from ./save/\")\n",
    "    model = AutoModelForMaskedLM.from_pretrained('./save/')\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    model = nn.DataParallel(model).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    pbar = tqdm(total = len(test_tgt))\n",
    "    for i in range(len(test_tgt)):\n",
    "        MaskNum = np.sum(np.array(test_src[i].split()) == \"[MASK]\")\n",
    "        if MaskNum > MaskNumConstraint: # MASK Length Constraint\n",
    "            pbar.update(1); continue\n",
    "        elif MaskNum == 0:\n",
    "            pbar.update(1); continue\n",
    "        DataDict_test = { \"test\": Dataset.from_dict({ \"text\": [' '.join(test_src[i].split()) ] }), }\n",
    "        datasets_test = DatasetDict(DataDict_test)\n",
    "\n",
    "        tokenized_datasets = datasets_test.map(\n",
    "            tokenize_function,\n",
    "            batched=False,\n",
    "            num_proc=1,\n",
    "        )\n",
    "\n",
    "        for cnt, x in enumerate(tokenized_datasets[\"test\"]):\n",
    "            with torch.no_grad():\n",
    "                MASK_idx = [ii for ii, iids in enumerate(x[\"input_ids\"])\n",
    "                            if iids == tokenizer.convert_tokens_to_ids([\"[MASK]\"])[0]]\n",
    "                outputs = model(torch.tensor(x[\"input_ids\"]).unsqueeze(0).to(device),)\n",
    "                p = []\n",
    "                pred_token = test_src[i].split()\n",
    "                tgt_token = test_tgt[i].split()\n",
    "\n",
    "            for m in MASK_idx:\n",
    "                predicted_index = torch.argmax(outputs[\"logits\"][0][m]).item()\n",
    "                pred_t = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "#                 pred_token[m] = '[[' + pred_t + ']]' # Visualization\n",
    "                pred_token[m] = pred_t\n",
    "                total += 1\n",
    "                if tgt_token[m] == pred_t:\n",
    "                    CorrectFlag = True\n",
    "                    correct += 1\n",
    "                ### Top-k\n",
    "                pred_topk = []; pred_ts = []\n",
    "                for n in range(1,10+1): # Starts from Top-1\n",
    "                    pred_topk = torch.argsort(-outputs[\"logits\"][0][m])[:n]\n",
    "                    pred_ts = tokenizer.convert_ids_to_tokens([t for t in pred_topk])\n",
    "                    if tgt_token[m] in pred_ts:\n",
    "                        correct_topk[n] += 1\n",
    "\n",
    "                exp_t = outputs[\"logits\"][0][m].cpu().numpy()\n",
    "                # https://huggingface.co/transformers/perplexity.html\n",
    "                prob = np.exp(exp_t[tokenizer.convert_tokens_to_ids(tgt_token[m])]/len(exp_t))\n",
    "                p.append(prob)\n",
    "                \n",
    "        if Verbose:\n",
    "            if i <= 10:\n",
    "                print(\"#Mask\", MaskNum)\n",
    "                ### Coloring\n",
    "                for t1, t2 in zip(test_src[i].split(), pred_token):\n",
    "                    if t1 == \"[PAD]\": break\n",
    "                    else:\n",
    "                        if t1 == \"[MASK]\":\n",
    "                            print(colored(t2, 'red'), end=' ')\n",
    "                        else:\n",
    "                            print(t2, end=' ')\n",
    "                print()\n",
    "                #####\n",
    "                for t1, t2 in zip(test_src[i].split(), test_tgt[i].split()):\n",
    "                    if t1 == \"[PAD]\": break\n",
    "                    else:\n",
    "                        if t1 == \"[MASK]\":\n",
    "                            print(colored(t2, 'blue'), end=' ')\n",
    "                        else:\n",
    "                            print(t2, end=' ')\n",
    "                print()\n",
    "                CorrectFlag = False\n",
    "\n",
    "        if p: perplexity_list.append(np.sum(p))\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    print(correct, '/', total, correct/total)\n",
    "    for n in range(1,10+1):\n",
    "        print(\"Top-\"+str(n), \"Accuracy\", correct_topk[n]/total)\n",
    "    print(\"Perplexity(MASK)\", np.mean(perplexity_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
